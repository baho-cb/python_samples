from sys import argv
import sys
import os
sys.path.insert(0,"/home/baho/Desktop/scripts")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages
import matplotlib.cm as cm
import argparse
import numpy as np
import gsd
import gsd.hoomd
from ClusterUtils import ClusterUtils
from ClusterNetwork import Cluster
import re


"""
May 30 2022
For clusters generated by hoomd-blue (rras_v5.hoomd) by adding 1 by 1
Assumes ther is only one cluster in the box.
The input gsd file structure should be : simulation-name_shape-id_#.gsd Underscores
are separators.
Run this one in a directory to make a data file containing all the info
about the clusters found
Each row in the output corresponds to one cluster, each cluster is described by
# simulation_id shape_id MaxDimension N_shape Avg-Degree EdgeFreq. Edge-Str_min Edge-Str_mid Edge-Str_max


"""

parser = argparse.ArgumentParser(description="Cluster analysis of a gsd file for a single frame")
non_opt = parser.add_argument_group("mandatory arguments")
non_opt.add_argument('-i', '--input', metavar="<dat>", type=str,nargs="+", dest="input_files",
required=True, help=".gsd files " )

non_opt.add_argument('-o', '--output', metavar="<dat>", type=str, dest="out_name",
required=True, help="the name of the output data file sth like 240x " )

non_opt.add_argument('--cutoff', metavar="<float>", type=float, dest="cutoff",
required=True, help=" cutoff for DBSCAN ", default = -1 )

non_opt.add_argument('--min_samples', metavar="<int>", type=int, dest="min_samples",
required=True, help=" min_samples for DBSCAN ..\
lower than this value wont count as a cluster but will be noise ",default=2)

non_opt.add_argument('-f', '--frame', metavar="<int>", type=int, dest="target_frame",
required=True, help=" - ",default = -1 )

non_opt.add_argument('--dummy', metavar="<int>", type=int, dest="dummy_type",
required=False, help="if there is a dummy particle type that you don't want to ..\
consider when calculating the clusters, specify it here - for example the particles ..\
that are filling the empty space inside the shapes should be dummy particles ",default = -1  )


args = parser.parse_args()
input_files = args.input_files
out_name = args.out_name
cutoff = args.cutoff
min_samples = args.min_samples
target_frame = args.target_frame
dummy_type = args.dummy_type

print("--- DBSCAN with ---")
print("Cutoff : ", cutoff)
print("Min_samples : ", min_samples)
print("Files : ", input_files)
print("Frame : ", target_frame )
print("Dummy type : ", dummy_type)
print("----------------------------")

clusters = []
sim_names = []

for i_f,input_file in enumerate(input_files):
    file_name = input_file[:-4]
    file = file_name.split("_")
    shape_id = file[1]
    shape_id = int(shape_id)
    cluster_utils = ClusterUtils(input_file,target_frame)
    cluster_utils.check_overlap()
    cluster_utils.remove_unattached(cutoff,min_samples)
    cluster_utils.dbscan(cutoff,min_samples)
    cluster_utils.setShapeId(shape_id)
    clusters.append(cluster_utils.getCluster())
    sim_names.append(file[0]+file[2])

    # sim_ids.append(int(re.search(r'\d+', input_file).group()))

sim_names_unq = list(set(sim_names))
data = [] ## matrix to be printed
for i,c in enumerate(clusters):
    sim_id = sim_names_unq.index(sim_names[i])
    c.setSimId(sim_id)
    info = c.getInfo()
    data.append(info)

out_name = out_name + ".cl_data"
data = np.array(data)
np.savetxt(out_name,data,fmt="%d %d %.2f %d %.3f %.3f %.3f %.3f %.3f ",header="# sim_id shape_id MaxDist ..\
N_shape Avg-Degree EdgeFreq. Edge-Str_min Edge-Str_mid Edge-Str_max)")

print("Simulation-Name <-> SimId")
for i,name in enumerate(sim_names_unq):
    print("%s <-> %d"%(name,i) )



exit()
